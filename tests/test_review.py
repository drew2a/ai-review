import argparse
from pathlib import Path
from unittest import mock
from unittest.mock import Mock, patch

import pytest
from jinja2 import Environment

from review import extract_json, get_model, process_review, supported_models, parse_author_customization, get_author_specific_prompt_additions


def test_openai_create_header():
    """ Test OpenAI header creation """
    model = get_model('gpt-4o')

    expected = {
        'Api-Version': '1.0',
        'Authorization': 'Bearer example_key',
        'Content-Type': 'application/json',
        'api-key': 'example_key'
    }

    assert supported_models[model]['header']('example_key', '1.0') == expected


def test_claude_create_header():
    """ Test Claude header creation """
    model = get_model('claude-3-5-sonnet')

    expected = {
        'anthropic-version': '1.0',
        'Content-Type': 'application/json',
        'x-api-key': 'example_key'
    }
    assert supported_models[model]['header']('example_key', '1.0') == expected


def test_get_model_unsupported_pattern():
    """ Test get_model raises ValueError for unsupported patterns """
    with pytest.raises(ValueError) as exc_info:
        get_model('unsupported-model')
    expected_message = "Unsupported model pattern: unsupported-model. Supported patterns are: ['^gpt-4', '^o1', '^claude-3', '^gemini-2']"
    assert str(exc_info.value) == expected_message


@patch.object(Path, 'read_text', Mock(return_value='prompt'))
@patch.object(Environment, 'get_template', Mock(return_value=Mock(render=Mock(return_value='user_prompt'))))
@patch('requests.post')
def test_process_review(mock_post):
    """ Test the process_review function """
    diff_content = "Sample diff content"
    args = argparse.Namespace(
        api_endpoint='https://api.test.com',
        api_key='test_key',
        api_version='v1',
        llm_model='gpt-4o',
        github_token='gh_token',
        debug='false',
        add_review_resolution='false',
        add_joke='true',
        author_customization='',
    )

    expected_response = 'Review content generated by LLM.'

    mock_response = mock.Mock()
    mock_response.json.return_value = {'choices': [{'message': {'content': expected_response}}]}
    mock_response.raise_for_status = mock.Mock()
    mock_post.return_value = mock_response

    result = process_review('title', 'body', diff_content, 'test_author', args, False)

    assert result == expected_response
    mock_post.assert_called_once_with(
        args.api_endpoint,
        headers={
            'Authorization': f"Bearer {args.api_key}",
            "api-key": args.api_key,
            'Api-Version': args.api_version,
            'Content-Type': 'application/json'
        },
        json={
            "model": args.llm_model,
            "messages": [
                {"role": 'system', "content": "prompt\nprompt"},
                {'role': 'user', 'content': 'user_prompt'}
            ]
        }
    )


def test_extract_json():
    text = '''
    any
    {
    json {
    }
    }
    text
    '''

    expected = '''{
    json {
    }
    }'''

    assert extract_json(text) == expected


def test_extract_no_text():
    assert not extract_json(None)
    assert extract_json('') == ''


def test_parse_author_customization_empty():
    """ Test parsing empty author customization """
    assert parse_author_customization('') == {}
    assert parse_author_customization(None) == {}
    assert parse_author_customization('   ') == {}


def test_parse_author_customization_valid_yaml():
    """ Test parsing valid YAML author customization """
    yaml_config = """
torvalds: "Be extra careful with this user's code"
defunkt: "Quick review for this user"
"""
    result = parse_author_customization(yaml_config)
    expected = {
        'torvalds': "Be extra careful with this user's code",
        'defunkt': "Quick review for this user"
    }
    assert result == expected


def test_parse_author_customization_invalid_yaml():
    """ Test parsing invalid YAML returns empty dict """
    invalid_yaml = "invalid: yaml: content: ["
    result = parse_author_customization(invalid_yaml)
    assert result == {}


def test_get_author_specific_prompt_additions_direct_match():
    """ Test getting prompt additions for direct author match """
    customizations = {
        'torvalds': "Be extra careful",
        'defunkt': "Quick review"
    }
    result = get_author_specific_prompt_additions('torvalds', customizations)
    assert result == "Be extra careful"
    
    result = get_author_specific_prompt_additions('defunkt', customizations)
    assert result == "Quick review"


def test_get_author_specific_prompt_additions_no_match():
    """ Test getting prompt additions with no match - returns empty string """
    customizations = {
        'torvalds': "Be extra careful"
    }
    result = get_author_specific_prompt_additions('unknown_user', customizations)
    assert result == ""


def test_get_author_specific_prompt_additions_empty():
    """ Test getting prompt additions with empty inputs """
    assert get_author_specific_prompt_additions('', {}) == ""
    assert get_author_specific_prompt_additions('user', {}) == ""
    assert get_author_specific_prompt_additions('', {'user': 'test'}) == ""
